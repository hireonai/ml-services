{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\~rpc'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflowjs 3.18.0 requires packaging~=20.9, but you have packaging 24.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chromadb\n",
    "import os\n",
    "import pymongo\n",
    "\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "print(load_dotenv())\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '../credentials/ai_platform.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>jobPosition</th>\n",
       "      <th>jobDescList</th>\n",
       "      <th>jobQualificationsList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68341f06d64eecb3953d58ee</td>\n",
       "      <td>Back End Developer</td>\n",
       "      <td>[Utilize languages like Go, PHP/Laravel, and P...</td>\n",
       "      <td>[Minimum Bachelor of Science in computer scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68341f06d64eecb3953d58ef</td>\n",
       "      <td>(Freelance) Sales Retail Mobile/Canvasser</td>\n",
       "      <td>[Retail Sales Mobile akan bertanggung jawab un...</td>\n",
       "      <td>[Pendidikan minimal SMA/SMK/sederajat., Memili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68341f06d64eecb3953d58f0</td>\n",
       "      <td>Creative Lead</td>\n",
       "      <td>[Membuat laporan weekly &amp; monthly, Memberikan ...</td>\n",
       "      <td>[Pendidikan minimal S1 Ilmu Komunikasi / Marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68341f06d64eecb3953d58f1</td>\n",
       "      <td>Social Media Specialist</td>\n",
       "      <td>[We are looking for a Social Media Specialist ...</td>\n",
       "      <td>[Bachelor's degree in Marketing, Communication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68341f06d64eecb3953d58f2</td>\n",
       "      <td>HRGA Staff area Padalarang Kabupaten Bandung B...</td>\n",
       "      <td>[Membantu perekrutan dan pengelolaan operasion...</td>\n",
       "      <td>[Pengalaman HRGA minimal 1 Tahun, Memiliki kem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  68341f06d64eecb3953d58ee   \n",
       "1  68341f06d64eecb3953d58ef   \n",
       "2  68341f06d64eecb3953d58f0   \n",
       "3  68341f06d64eecb3953d58f1   \n",
       "4  68341f06d64eecb3953d58f2   \n",
       "\n",
       "                                         jobPosition  \\\n",
       "0                                 Back End Developer   \n",
       "1          (Freelance) Sales Retail Mobile/Canvasser   \n",
       "2                                      Creative Lead   \n",
       "3                            Social Media Specialist   \n",
       "4  HRGA Staff area Padalarang Kabupaten Bandung B...   \n",
       "\n",
       "                                         jobDescList  \\\n",
       "0  [Utilize languages like Go, PHP/Laravel, and P...   \n",
       "1  [Retail Sales Mobile akan bertanggung jawab un...   \n",
       "2  [Membuat laporan weekly & monthly, Memberikan ...   \n",
       "3  [We are looking for a Social Media Specialist ...   \n",
       "4  [Membantu perekrutan dan pengelolaan operasion...   \n",
       "\n",
       "                               jobQualificationsList  \n",
       "0  [Minimum Bachelor of Science in computer scien...  \n",
       "1  [Pendidikan minimal SMA/SMK/sederajat., Memili...  \n",
       "2  [Pendidikan minimal S1 Ilmu Komunikasi / Marke...  \n",
       "3  [Bachelor's degree in Marketing, Communication...  \n",
       "4  [Pengalaman HRGA minimal 1 Tahun, Memiliki kem...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pymongo.MongoClient(os.getenv(\"MONGO_URI\"))[\"hireonai\"]\n",
    "jobs_collection = db.get_collection('jobs')\n",
    "cursor = jobs_collection.find({})  # Query all documents\n",
    "jobs_df = pd.DataFrame(list(cursor))[['_id', 'jobPosition', 'jobDescList', 'jobQualificationsList']]\n",
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2697 2697 2697\n",
      "['68341f06d64eecb3953d58ee', '68341f06d64eecb3953d58ef', '68341f06d64eecb3953d58f0', '68341f06d64eecb3953d58f1', '68341f06d64eecb3953d58f2']\n",
      "['Back End Developer', '(Freelance) Sales Retail Mobile/Canvasser', 'Creative Lead', 'Social Media Specialist', 'HRGA Staff area Padalarang Kabupaten Bandung Barat']\n",
      "['Job Desc:\\n- Utilize languages like Go, PHP/Laravel, and Python for backend development and maintenance.\\n- Manage SQL (MySQL, PostgreSQL) and NoSQL (MongoDB) databases for data storage and retrieval.\\n- Implement and manage messaging systems such as Kafka, RabbitMQ, and Redis for enhanced performance.\\n- Design and implement APIs for effective frontend-backend communication.\\n- Regularly use Git for code versioning and collaborative development.\\n- Apply clean code architecture practices to ensure code quality and maintainability.\\n- Use object-oriented programming techniques for modular and scalable code development.\\n- Understand and implement Entity Relationship Diagrams and database normalization for efficient database design.\\nJob Qualification:\\n- Minimum Bachelor of Science in computer science, software engineering, programming, or equivalent\\n- Proficiency with languages such as\\xa0Go, PHP/Laravel, and Python\\n- Understanding\\xa0\\xa0Entity Relationship Diagram and normalization\\n- Experience in SQL (my sql, postgresql) and no SQL (mongodb)\\n- Have experience in implement messages broker (kafka), messages queue (rabbitmq) and redis is a plus\\n- Experience with the design and implementation of APIs\\n- Understanding of code versioning tools such as Git\\n- Understanding\\xa0of clean code architecture is\\xa0a plus\\n- Understanding of object-oriented programming\\n', 'Job Desc:\\n- Retail Sales Mobile akan bertanggung jawab untuk mencari dan menjalin hubungan dengan klien bisnis baru (perusahaan, organisasi, pemerintah, dsb). Tugas utama posisi ini adalah mencari dan menghasilkan prospek, membangun hubungan, dan mengubah peluang menjadi sales dengan mempromosikan produk torch.id kepada bisnis lain.\\nJob Qualification:\\n- Pendidikan minimal SMA/SMK/sederajat.\\n- Memiliki pengalaman minimal 1 tahun sebagai sales B2B.\\n- Memiliki database network di industri, pemerintah, dsb.\\n- Memiliki dan bisa mengendarai kendaraan pribadi.\\n- Memiliki kemampuan komunikasi yang baik.\\n- Bersedia bekerja mobile.\\n- Aktif, jujur, memiliki inisiatif, teliti, dan bertanggung jawab.\\n- Berdomisili di sekitar \\n', 'Job Desc:\\n- Membuat laporan weekly & monthly\\n- Memberikan training & mentoring kepada Staff\\n- Melakukan controlling pekerjaan kepada keseluruhan tim\\n- Melakukan quality checking konten & desain\\n- Membuat konsep feed untuk Marketplace & Social Media dan Membuat konsep desain untuk promosi twindate, mid month, & payday\\n- Membuat konsep photo & video shoot per bulan untuk produk maupun talent\\n- Melakukan morning briefing setiap hari kepada tim\\n- Membuat timeline campaign dan content planning\\n- Membuat & controlling budgeting untuk brand marketing\\n- Melakukan quality checking untuk video KOL\\n- Mengadakan monthly meeting dengan tim untuk evaluasi kerja\\n- Presentasi pengajuan untuk approval campaign\\n- Riset konten dan desain\\n- Membuat plan untuk campaign atau campaign semester atau quarter\\nJob Qualification:\\n- Pendidikan minimal S1 Ilmu Komunikasi / Marketing\\n- Pengalaman minimal 3 tahun di bidang yang retail , dan sebelumnya pernah menjadi SPV\\n- Diutamakan pernah bekerja dibidang skincare\\n- Memiliki pemahaman yang mendalam tentang digital marketing dan platform media sosial.\\n- Good Communication skill\\n- Creative & Analytical thinking\\n- Up to date dengan tren terbaru\\n- Memiliki Keterampilan berpikri strategis, analitis dan problem solving\\n- Mengikuti perkembangan terbaru dalam tren dan perilaku konsumen\\n- Memiliki leadership skill dan kemampuan management tim yang kuat\\n', \"Job Desc:\\n- We are looking for a Social Media Specialist to join our growing team! As a Social Media Specialist, you will play a vital role in shaping TORCH’s online presence, engaging with the target audience,, and driving digital marketing efforts, mainly on Instagram and X (past: Twitter).\\nJob Qualification:\\n- Bachelor's degree in Marketing, Communications, Digital Media, or a related field.\\n- Min. \\n- in social media management, preferably in the fashion or retail industry.\\n- Strong understanding of social media platforms, trends, and best practices.\\n- Excellent visual and written communication skills with a creative flair.\\n- Proficiency in using social media scheduling tools, analytics, and advertising platforms.\\n- Familiarity with graphic design tools for creating social media visuals.\\n- Knowledge of influencer marketing and experience in managing influencer collaborations.\\n- Ability to analyze data and extract actionable insights to improve social media performance.\\n- Adaptability to changing social media algorithms and industry trends.\\n- Customer-centric mindset with the ability to engage and connect with the target audience.\\n- Strong organizational and multitasking skills to manage multiple social media channels and campaigns simultaneously\\n\", 'Job Desc:\\n- Membantu perekrutan dan pengelolaan operasional;\\n- Berkoordinasi dengan departemen\\xa0terkait;\\n- Menjaga dan Mengorganisasi dokumen pekerja seperti informasi pribadi dan kontrak kerja;\\n- Memperbaharui database HR seperti dokumen Personal serta data karyawan baru dan yang lama;\\n- Pemeliharaan aset;\\n- Membantu urusan Perizinan Perusahaan;\\n- Membina hubungan baik dengan Suplier.\\nJob Qualification:\\n- Pengalaman HRGA minimal 1 Tahun\\n- Memiliki kemampuan Interview dan Pengelolaan Operasional\\n- Mahir mengendarai mobil, dan memiliki SIM A dan maupun SIM C aktif\\n- Berdomisili di Padalarang\\n']\n"
     ]
    }
   ],
   "source": [
    "all_id_list = jobs_df['_id'].astype(str).tolist()\n",
    "all_job_title_list = jobs_df['jobPosition'].tolist()\n",
    "all_job_desc_qual_list = jobs_df['jobDescListFormatted'].tolist()\n",
    "print(len(all_id_list), len(all_job_title_list), len(all_job_desc_qual_list))\n",
    "print(all_id_list[:5])\n",
    "print(all_job_title_list[:5])\n",
    "print(all_job_desc_qual_list[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.HttpClient(host=os.getenv(\"CHROMA_CLIENT_HOST\"), port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "response = client.models.embed_content(\n",
    "            model=\"text-multilingual-embedding-002\",\n",
    "            contents=all_job_title_list[0],  # Send only one item\n",
    "            config=types.EmbedContentConfig(\n",
    "                task_type=\"RETRIEVAL_DOCUMENT\",\n",
    "                title='Job Title',\n",
    "            ),\n",
    "        )\n",
    "        # Extract embedding from response and add to list\n",
    "embedding = response.embeddings[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  45%|████▌     | 5/11 [00:17<00:20,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1500 items. Adding 2 minute delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 11/11 [02:40<00:00, 14.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2697 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store job_title_embeddings\n",
    "job_title_embeddings = []\n",
    "\n",
    "# Split job titles into batches of 250\n",
    "batch_size = 250\n",
    "batches = [all_job_title_list[i:i + batch_size] for i in range(0, len(all_job_title_list), batch_size)]\n",
    "\n",
    "# Counter for processed items\n",
    "processed_count = 0\n",
    "\n",
    "# Process batches with progress bar\n",
    "for batch_idx, batch in enumerate(tqdm(batches, desc=\"Processing batches\")):\n",
    "    try:\n",
    "        response = client.models.embed_content(\n",
    "            model=\"text-multilingual-embedding-002\",\n",
    "            contents=batch,  # Send batch of items\n",
    "            config=types.EmbedContentConfig(\n",
    "                task_type=\"RETRIEVAL_DOCUMENT\",\n",
    "                title='Job Title',\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        # Extract embeddings from response and add to list\n",
    "        batch_embeddings = [embedding.values for embedding in response.embeddings]\n",
    "        job_title_embeddings.extend(batch_embeddings)\n",
    "        processed_count += len(batch)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {e}\")\n",
    "        # Fall back to processing one by one if batch fails\n",
    "        for job_title in batch:\n",
    "            try:\n",
    "                single_response = client.models.embed_content(\n",
    "                    model=\"text-multilingual-embedding-002\",\n",
    "                    contents=job_title,\n",
    "                    config=types.EmbedContentConfig(\n",
    "                        task_type=\"RETRIEVAL_DOCUMENT\",\n",
    "                        title='Job Title',\n",
    "                    ),\n",
    "                )\n",
    "                embedding = single_response.embeddings[0].values\n",
    "                job_title_embeddings.append(embedding)\n",
    "                processed_count += 1\n",
    "            except Exception as inner_e:\n",
    "                print(f\"Error processing '{job_title}': {inner_e}\")\n",
    "    \n",
    "    # Check if we need to add a delay (after every 1500 items)\n",
    "    if processed_count >= 1500:\n",
    "        delay_minutes = 2\n",
    "        print(f\"\\nProcessed {processed_count} items. Adding {delay_minutes} minute delay...\")\n",
    "        time.sleep(delay_minutes * 60)  # Convert minutes to seconds\n",
    "        processed_count = processed_count % 1500  # Keep only the remainder\n",
    "\n",
    "print(f\"Generated {len(job_title_embeddings)} embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.delete_collection('job_titles') if chroma_client.get_collection('job_titles') else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding to Chroma collection: 100%|██████████| 27/27 [01:04<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added data to collection in 27 batches\n",
      "Collection count: 2697\n"
     ]
    }
   ],
   "source": [
    "# Batch size for adding to collection\n",
    "batch_size = 100\n",
    "\n",
    "# Split all data into manageable batches\n",
    "total_items = len(all_id_list)\n",
    "batches = [(i, min(i + batch_size, total_items)) for i in range(0, total_items, batch_size)]\n",
    "\n",
    "# Create or get a collection\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"job_titles\",\n",
    "    embedding_function=embedding_functions.GoogleGenerativeAiEmbeddingFunction(\n",
    "        model_name=\"text-multilingual-embedding-002\",\n",
    "        task_type=\"RETRIEVAL_DOCUMENT\",\n",
    "        api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add documents in batches\n",
    "for start_idx, end_idx in tqdm(batches, desc=\"Adding to Chroma collection\"):\n",
    "    batch_ids = [str(id) for id in all_id_list[start_idx:end_idx]]\n",
    "    batch_documents = all_job_title_list[start_idx:end_idx]\n",
    "    batch_embeddings = job_title_embeddings[start_idx:end_idx]\n",
    "    \n",
    "    try:\n",
    "        collection.add(\n",
    "            ids=batch_ids,\n",
    "            documents=batch_documents,\n",
    "            embeddings=batch_embeddings\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding batch {start_idx}:{end_idx}: {e}\")\n",
    "\n",
    "print(f\"Added data to collection in {len(batches)} batches\")\n",
    "print(f\"Collection count: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "query_embeddings = client.models.embed_content(\n",
    "    model=\"text-multilingual-embedding-002\",\n",
    "    contents=[\"software developer\"],\n",
    "    config=types.EmbedContentConfig(\n",
    "        task_type=\"RETRIEVAL_DOCUMENT\",\n",
    "        title='Job Title',\n",
    "    )).embeddings[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Example query\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embeddings],\n",
    "    n_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▉         | 4/43 [00:09<01:27,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 320 items. Adding 1.5 minute delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|██        | 9/43 [01:51<05:05,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 340 items. Adding 1.5 minute delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 14/43 [03:33<04:49,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 360 items. Adding 1.5 minute delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 18/43 [05:15<05:47, 13.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 316 items. Adding 1.5 minute delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 23/43 [06:57<03:34, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 336 items. Adding 1.5 minute delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▌   | 28/43 [08:38<02:31, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 356 items. Adding 1.5 minute delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 32/43 [10:17<02:25, 13.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 312 items. Adding 1.5 minute delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 37/43 [12:00<01:04, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 332 items. Adding 1.5 minute delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 43/43 [13:48<00:00, 19.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2697 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delay_minutes = 1.5\n",
    "\n",
    "time.sleep(delay_minutes * 60)  # Convert minutes to seconds# Create empty list to store job_desc_req_embeddings\n",
    "\n",
    "job_desc_req_embeddings = []\n",
    "\n",
    "# Split job titles into batches of 250\n",
    "batch_size = 64\n",
    "batches = [all_job_desc_qual_list[i:i + batch_size] for i in range(0, len(all_job_desc_qual_list), batch_size)]\n",
    "\n",
    "# Counter for processed items\n",
    "processed_count = 0\n",
    "\n",
    "# Process batches with progress bar\n",
    "for batch_idx, batch in enumerate(tqdm(batches, desc=\"Processing batches\")):\n",
    "    try:\n",
    "        response = client.models.embed_content(\n",
    "            model=\"text-multilingual-embedding-002\",\n",
    "            contents=batch,  # Send batch of items\n",
    "            config=types.EmbedContentConfig(\n",
    "                task_type=\"RETRIEVAL_DOCUMENT\",\n",
    "                title='Job Description and Qualification',\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        # Extract embeddings from response and add to list\n",
    "        batch_embeddings = [embedding.values for embedding in response.embeddings]\n",
    "        job_desc_req_embeddings.extend(batch_embeddings)\n",
    "        processed_count += len(batch)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {e}\")\n",
    "        # Fall back to processing one by one if batch fails\n",
    "        for job_title in batch:\n",
    "            try:\n",
    "                single_response = client.models.embed_content(\n",
    "                    model=\"text-multilingual-embedding-002\",\n",
    "                    contents=job_title,\n",
    "                    config=types.EmbedContentConfig(\n",
    "                        task_type=\"RETRIEVAL_DOCUMENT\",\n",
    "                        title='Job Title',\n",
    "                    ),\n",
    "                )\n",
    "                embedding = single_response.embeddings[0].values\n",
    "                job_desc_req_embeddings.append(embedding)\n",
    "                processed_count += 1\n",
    "            except Exception as inner_e:\n",
    "                print(f\"Error processing '{job_title}': {inner_e}\")\n",
    "    \n",
    "    # Check if we need to add a delay (after every 1500 items)\n",
    "    if processed_count >= 300:\n",
    "        delay_minutes = 1.5\n",
    "        print(f\"\\nProcessed {processed_count} items. Adding {delay_minutes} minute delay...\")\n",
    "        time.sleep(delay_minutes * 60)  # Convert minutes to seconds\n",
    "        processed_count = processed_count % 300  # Keep only the remainder\n",
    "\n",
    "print(f\"Generated {len(job_desc_req_embeddings)} embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding to Chroma collection: 100%|██████████| 27/27 [00:55<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added data to collection in 27 batches\n",
      "Collection count: 2697\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    chroma_client.delete_collection('job_desc_req')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Batch size for adding to collection\n",
    "batch_size = 100\n",
    "\n",
    "# Split all data into manageable batches\n",
    "total_items = len(all_id_list)\n",
    "batches = [(i, min(i + batch_size, total_items)) for i in range(0, total_items, batch_size)]\n",
    "\n",
    "# Create or get a collection\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"job_desc_req\",\n",
    "    embedding_function=embedding_functions.GoogleGenerativeAiEmbeddingFunction(\n",
    "        model_name=\"text-multilingual-embedding-002\",\n",
    "        task_type=\"RETRIEVAL_DOCUMENT\",\n",
    "        api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add documents in batches\n",
    "for start_idx, end_idx in tqdm(batches, desc=\"Adding to Chroma collection\"):\n",
    "    batch_ids = [str(id) for id in all_id_list[start_idx:end_idx]]\n",
    "    batch_documents = all_job_title_list[start_idx:end_idx]\n",
    "    batch_embeddings = job_title_embeddings[start_idx:end_idx]\n",
    "    \n",
    "    try:\n",
    "        collection.add(\n",
    "            ids=batch_ids,\n",
    "            documents=batch_documents,\n",
    "            embeddings=batch_embeddings\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding batch {start_idx}:{end_idx}: {e}\")\n",
    "\n",
    "print(f\"Added data to collection in {len(batches)} batches\")\n",
    "print(f\"Collection count: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=job_desc_req),\n",
       " Collection(name=try_gemini_embedding),\n",
       " Collection(name=job_titles)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_client.list_collections()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
